{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca339c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "import json\n",
    "import os\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import prewitt_h, prewitt_v\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddd524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the xBD dataset images\n",
    "def load_images(image_path, image_filenames):\n",
    "    images = []\n",
    "    for filename in image_filenames:\n",
    "        image = cv2.imread(os.path.join(image_path, filename))  # Load image using OpenCV\n",
    "        images.append(image)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08603292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the corresponding GeoJSON files and extract the building polygons\n",
    "def load_gis_data(geojson_path):\n",
    "    geojson_filenames = os.listdir(geojson_path)  \n",
    "    polygons = []\n",
    "    for filename in geojson_filenames:\n",
    "        with open(os.path.join(geojson_path, filename)) as file:\n",
    "            data = json.load(file)\n",
    "            features = data['features']\n",
    "            for feature in features:\n",
    "                if 'wkt' in feature:\n",
    "                    wkt_string = feature['wkt']\n",
    "                    polygon = Polygon(wkt_string)\n",
    "                    polygons.append(polygon)\n",
    "    gis_data = gpd.GeoDataFrame(geometry=polygons)\n",
    "    return gis_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f99393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the image: convert to grayscale and resize\n",
    "def preprocess_image(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    resized_image = cv2.resize(gray_image, (224, 224))\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d61ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract texture features using Local Binary Patterns (LBP)\n",
    "def extract_texture_features(image):\n",
    "    lbp_image = local_binary_pattern(image, P=8, R=1, method='uniform')\n",
    "    hist, _ = np.histogram(lbp_image.ravel(), bins=np.arange(0, 10), density=True)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e2dfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract edge features using Prewitt filters\n",
    "def extract_edge_features(image):\n",
    "    edges_h = prewitt_h(image)\n",
    "    edges_v = prewitt_v(image)\n",
    "    edge_features = np.hstack((edges_h.ravel(), edges_v.ravel()))\n",
    "    return edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba94509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract color features using GLCM\n",
    "def extract_color_features(image):\n",
    "    gray_image = rgb2gray(image)\n",
    "    glcm = greycomatrix((gray_image * 255).astype(np.uint8), distances=[5], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    contrast = greycoprops(glcm, 'contrast')[0, 0]\n",
    "    homogeneity = greycoprops(glcm, 'homogeneity')[0, 0]\n",
    "    energy = greycoprops(glcm, 'energy')[0, 0]\n",
    "    correlation = greycoprops(glcm, 'correlation')[0, 0]\n",
    "    color_features = np.array([contrast, homogeneity, energy, correlation])\n",
    "    return color_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e9e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if an image overlaps with any damaged area in the GIS data\n",
    "def image_overlaps_with_damaged_area(image_filename, gis_data):\n",
    "    geojson_filename = image_filename.replace('_post_', '_pre_').replace('.png', '.json')\n",
    "    geojson_filepath = os.path.join(geojson_path, geojson_filename)\n",
    "    with open(geojson_filepath) as file:\n",
    "        data = json.load(file)\n",
    "        features = data['features']\n",
    "        for feature in features:\n",
    "            if 'wkt' in feature:\n",
    "                wkt_string = feature['wkt']\n",
    "                polygon = Polygon(wkt_string)\n",
    "                if polygon.intersects(gis_data.geometry):\n",
    "                    return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61161c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the paths to the xBD dataset images and corresponding GeoJSON files\n",
    "image_path = 'train/images/'\n",
    "geojson_path = 'train/labels/'\n",
    "\n",
    "# Load the images and GIS data\n",
    "image_filenames = os.listdir(image_path)\n",
    "images = load_images(image_path, image_filenames)\n",
    "gis_data = load_gis_data(geojson_path)\n",
    "\n",
    "# Extract features and labels for each image\n",
    "features = []\n",
    "labels = []\n",
    "for image, filename in zip(images, image_filenames):\n",
    "    preprocessed_image = preprocess_image(image)\n",
    "    texture_features = extract_texture_features(preprocessed_image)\n",
    "    edge_features = extract_edge_features(preprocessed_image)\n",
    "    color_features = extract_color_features(image)\n",
    "    feature_vector = np.concatenate((texture_features, edge_features, color_features))\n",
    "    features.append(feature_vector)\n",
    "    if \"_post_\" in filename:\n",
    "        labels.append(1)  # Damaged area\n",
    "    else:\n",
    "        labels.append(0)  # Not damaged area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc688cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features and labels to NumPy arrays\n",
    "X = np.array(features)\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dbf24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the class distribution\n",
    "class_counts = np.bincount(y)\n",
    "if class_counts.shape[0] < 2:\n",
    "    raise ValueError(\"The dataset should have at least two classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0562b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform data balancing using RandomOverSampler if necessary\n",
    "if np.min(class_counts) < 2:\n",
    "    oversampler = RandomOverSampler(random_state=42)\n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
    "else:\n",
    "    X_resampled, y_resampled = X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f15a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the feature and label arrays with the resampled data\n",
    "X = X_resampled\n",
    "y = y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13098f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db766cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the feature array for use with CNN\n",
    "num_samples, feature_shape = X.shape\n",
    "X = X.reshape(num_samples, feature_shape, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b9d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoding\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e31420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ResNet50 model\n",
    "input_shape = (16, 16, 1)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958ae863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e902765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff5c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d080bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e6483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
